import json
import os
import subprocess
import threading
from sqlalchemy.orm import Session
from datetime import date, timedelta

from app.models.app_usage_raw import AppUsageRaw
from app.models.prediction_logs import PredictionLog
from app.models.emotion_status_logs import EmotionStatusLog
from app.services.message_manager import MessageManager
from app.services.notification_service import (
    can_send_notification,
    save_notification_log,
)

# í˜„ì¬ íŒŒì¼ ìœ„ì¹˜: v0.6src/backend/app/services/prediction_engine.py
CURRENT_FILE = os.path.abspath(__file__)

# backend/app/services â†’ backend/app â†’ backend â†’ v0.7src
BASE_DIR = os.path.dirname(
    os.path.dirname(
        os.path.dirname(
            os.path.dirname(CURRENT_FILE)
        )
    )
)

# v0.7src/backend/ai_module/predict.py
AI_SCRIPT = os.path.join(BASE_DIR, "backend", "ai_module", "predict.py")
AI_SCRIPT = "/home/t25335/v0.7src/backend/ai_module/predict.py"

print("[DEBUG] USING prediction_engine.py AT:", __file__)
print("[DEBUG] BASE_DIR:", BASE_DIR)
print("[DEBUG] AI_SCRIPT:", AI_SCRIPT)


from app.utils.pattern_analyzer import analyze_patterns
import random

# Global Lock to prevent concurrent GPU access
_ai_execution_lock = threading.Lock()

class PredictionEngine:

    # 1) ìµœê·¼ ì‚¬ìš© ê¸°ë¡ ì¡°íšŒ
    @staticmethod
    def fetch_recent_usage(user_id: int, db: Session):
        # Enforce Standard Window: Provide data for "Yesterday" (00:00~23:59)
        # to predict "Today".
        today = date.today()
        target_date = today - timedelta(days=1)

        rows = (
            db.query(AppUsageRaw)
            .filter(
                AppUsageRaw.user_id == user_id,
                AppUsageRaw.usage_date == target_date
            )
            .order_by(AppUsageRaw.usage_date.asc(), AppUsageRaw.start_time.asc())
            .all()
        )

        return [
            {
                "usage_date": str(r.usage_date),
                "category": r.category,
                "package_name": r.package_name,
                "duration_ms": r.duration_ms,
                "start_time": str(r.start_time) if r.start_time else None,
            }
            for r in rows
        ]

    # ... (call_ai_engine, determine_level, get_mood_description, get_recommendations omitted - no changes needed)


    # 2) AI ì—”ì§„ subprocess í˜¸ì¶œ (Existing logic kept for Risk Score)
    @staticmethod
    def call_ai_engine(emotion: str, status: str, seq_data: list):
        # predict_risk.py ì— JSONì„ stdinìœ¼ë¡œ ë³´ë‚´ê³  stdoutì—ì„œ ê²°ê³¼ ë°›ê¸°
        
        input_json = json.dumps({
            "emotion": emotion,
            "status": status,
            "seq_data": seq_data,
        })

        try:
            # Acquire Lock before running subprocess
            # This serializes execution: User B waits until User A finishes.
            with _ai_execution_lock:
                result = subprocess.run(
                    ["python3", AI_SCRIPT],
                    input=input_json.encode(),
                    capture_output=True,
                    timeout=20
                )
        except Exception as e:
            print(f"[AI ERROR] {e}")
            return {"risk_score": 50.0}

        if result.returncode != 0:
            print("[AI ENGINE FAILED]", result.stderr.decode())
            return {"risk_score": 50.0}

        try:
            return json.loads(result.stdout.decode())
        except Exception as e:
            print(f"[AI JSON ERROR] {e}")
            print(f"[AI STDOUT] {result.stdout.decode()}")
            return {"risk_score": 50.0}

    # 3) ìœ„í—˜ ë ˆë²¨ íŒì •
    @staticmethod
    def determine_level(score: float):
        if score >= 0.70:
            return "DANGER"
        elif score >= 0.40:
            return "CAUTION"
        return "SAFE"

    # 4) ê¸°ë¶„/ìƒíƒœ ì„¤ëª… ìƒì„±
    @staticmethod
    def get_mood_description(emotion: str, status: str):
        # íŒŒë¼ë¯¸í„°ì— ë”°ë¼ ë©˜íŠ¸ ìƒì„±
        desc = ""
        if emotion == "GOOD":
            desc = "ê¸°ë¶„ì´ ì¢‹ì€ í•˜ë£¨ë„¤ìš”! "
        elif emotion == "NORMAL":
            desc = "í‰ë²”í•˜ê³  ë¬´ë‚œí•œ í•˜ë£¨ì…ë‹ˆë‹¤. "
        elif emotion == "BAD":
            desc = "ê¸°ë¶„ì´ ë‹¤ì†Œ ì €ì¡°í•œ ë‚ ì´ë„¤ìš”. "
        
        if status == "BUSY":
            desc += "ë°”ìœ ì¼ì • ì†ì—ì„œë„ í‹ˆí‹ˆì´ íœ´ì‹ì„ ì±™ê¸°ì„¸ìš”."
        elif status == "FREE":
            desc += "ì—¬ìœ ë¡œìš´ ì‹œê°„, ë‚˜ë§Œì˜ ì·¨ë¯¸ ìƒí™œì„ ì¦ê²¨ë³´ëŠ” ê±´ ì–´ë–¨ê¹Œìš”?"
        else:
            desc += "ì˜¤ëŠ˜ í•˜ë£¨ë„ í™”ì´íŒ…í•˜ì„¸ìš”."
            
        return desc

    # 5) ê¸°ë¶„/ìƒíƒœ ì„¤ëª… ìƒì„¸ ìƒì„± (New API)
    @staticmethod
    def get_mood_details(emotion: str, status: str):
        # 1. Title Construction
        # Icon Map
        icons = {"GOOD": "ğŸ˜€", "NORMAL": "ğŸ˜", "BAD": "ğŸ˜"}
        emo_kr = {"GOOD": "ì¢‹ìŒ", "NORMAL": "í‰ë²”", "BAD": "ë‚˜ì¨"}
        stat_kr = {"BUSY": "ë°”ì¨", "FREE": "ì—¬ìœ ë¡œì›€"}
        
        icon = icons.get(emotion, "ğŸ˜")
        e_text = emo_kr.get(emotion, emotion)
        s_text = stat_kr.get(status, status)
        
        title = f"{icon} {e_text} Â· {s_text}"
        
        # 2. Description Construction
        desc = ""
        if emotion == "BAD":
            if status == "FREE":
                desc = "ì˜¤ëŠ˜ì€ ê¸°ë¶„ì´ ì¢‹ì§€ ì•Šê³  ì—¬ìœ ë¡œìš´ ë‚ ì´ì—ìš”. ì ê¹ ì‚°ì±…ì„ í•´ë³´ëŠ” ê²ƒì´ ë„ì›€ì´ ë  ìˆ˜ ìˆì–´ìš”."
            else: # BUSY
                desc = "ê¸°ë¶„ì´ ì €ì¡°í•œë° ì¼ì •ê¹Œì§€ ë°”ì˜ì‹œêµ°ìš”. í‹ˆí‹ˆì´ ì‹¬í˜¸í¡ì„ í•˜ë©° ë§ˆì¸ë“œì»¨íŠ¸ë¡¤ì´ í•„ìš”í•´ìš”."
        elif emotion == "GOOD":
            if status == "FREE":
                desc = "ê¸°ë¶„ë„ ì¢‹ê³  ì‹œê°„ë„ ì—¬ìœ ë¡œìš´ ì™„ë²½í•œ í•˜ë£¨! ìƒˆë¡œìš´ ì·¨ë¯¸ë‚˜ ìš´ë™ì„ ì‹œì‘í•´ë³´ëŠ” ê±´ ì–´ë–¨ê¹Œìš”?"
            else: # BUSY
                desc = "í™œê¸°ì°¬ ì—ë„ˆì§€ë¡œ ë°”ìœ í•˜ë£¨ë„ ê±°ëœ¬íˆ ì´ê²¨ë‚¼ ìˆ˜ ìˆì„ ê±°ì˜ˆìš”! ë‹¤ë§Œ ë¬´ë¦¬í•˜ì§€ ì•Šë„ë¡ ì£¼ì˜í•˜ì„¸ìš”."
        else: # NORMAL
            if status == "FREE":
                desc = "ì°¨ë¶„í•˜ê³  ì—¬ìœ ë¡œìš´ í•˜ë£¨ë„¤ìš”. ì½ê³  ì‹¶ì—ˆë˜ ì±…ì„ ì½ê±°ë‚˜ ë°€ë¦° ì˜í™”ë¥¼ ë³´ëŠ” ê±´ ì–´ë•Œìš”?"
            else: # BUSY
                desc = "í‰ë²”í•œ í•˜ë£¨ì§€ë§Œ ë°”ìœ ì¼ì •ì´ ê¸°ë‹¤ë¦¬ê³  ìˆë„¤ìš”. ì°¨ê·¼ì°¨ê·¼ í•˜ë‚˜ì”© í•´ê²°í•´ ë‚˜ê°€ë³´ì„¸ìš”."
                
        return {"title": title, "description": desc}

    # 6) ì¶”ì²œ í–‰ë™ ìƒì„±
    @staticmethod
    def get_recommendations(level: str, emotion: str):
        if level == "SAFE":
            return [{
                "title": "ğŸ‰ í›Œë¥­í•´ìš”!",
                "description": "ì˜¤ëŠ˜ì€ ì‚¬ìš©ëŸ‰ì´ ì ì„ ê²ƒìœ¼ë¡œ ì˜ˆìƒë¼ìš”. ì´ëŒ€ë¡œ ì¢‹ì€ ìŠµê´€ì„ ìœ ì§€í•˜ë©° ì¦ê±°ìš´ í•˜ë£¨ ë³´ë‚´ì„¸ìš”!"
            }]
            
        # Pool for CAUTION / DANGER
        pool = [
            {"title": "ğŸš¶â€â™‚ï¸ ì‚°ì±…í•˜ê¸°", "description": "ì ê¹ 15ë¶„ ì •ë„ ì‚°ì±…ì„ í•˜ë©´ ìˆí¼ ì½˜í…ì¸  ì‚¬ìš© ì¶©ë™ì´ ê°ì†Œí•©ë‹ˆë‹¤."},
            {"title": "ğŸ˜Œ íœ´ì‹ ì·¨í•˜ê¸°", "description": "ì €ë… ì‹œê°„ëŒ€ ì „ì— ì¶©ë¶„í•œ íœ´ì‹ì„ ì·¨í•˜ë©´ ê³¼ë„í•œ ì•± ì‚¬ìš©ì„ ì˜ˆë°©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."},
            {"title": "ğŸ“± ë””ì§€í„¸ ë””í†¡ìŠ¤", "description": "20ì‹œ ì´í›„ ìŠ¤ë§ˆíŠ¸í°ì„ ë©€ë¦¬ ë‘ê³  ë…ì„œë‚˜ ëª…ìƒ ë“± ë‹¤ë¥¸ í™œë™ì„ í•´ë³´ì„¸ìš”."},
            {"title": "ğŸ“– ë…ì„œí•˜ê¸°", "description": "ìˆí¼ ì½˜í…ì¸  ëŒ€ì‹  ì±…ì„ ì½ìœ¼ë©´ ìˆ˜ë©´ì˜ ì§ˆì´ ê°œì„ ë˜ê³  ë§ˆìŒì˜ ì•ˆì •ì„ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."},
            {"title": "ğŸ§˜ 10ë¶„ ëª…ìƒ", "description": "ì ì‹œ ëˆˆì„ ê°ê³  í˜¸í¡ì— ì§‘ì¤‘í•´ë³´ì„¸ìš”. ë³µì¡í•œ ë¨¸ë¦¿ì†ì„ ë¹„ìš°ëŠ” ë° í° ë„ì›€ì´ ë©ë‹ˆë‹¤."},
            {"title": "ğŸµ ë”°ëœ»í•œ ì°¨ ë§ˆì‹œê¸°", "description": "ë”°ëœ»í•œ ì°¨ í•œ ì”ì˜ ì—¬ìœ ë¥¼ ê°€ì ¸ë³´ì„¸ìš”. ìŠ¤ë§ˆíŠ¸í° ì—†ì´ ì˜¤ë¡¯ì´ ë‚˜ì—ê²Œ ì§‘ì¤‘í•˜ëŠ” ì‹œê°„ì…ë‹ˆë‹¤."},
            {"title": "ğŸ—£ï¸ ì¹œêµ¬ì™€ ëŒ€í™”í•˜ê¸°", "description": "ë©”ì‹ ì € ëŒ€ì‹  ì§ì ‘ ë§Œë‚˜ê±°ë‚˜ ì „í™”ë¡œ ëŒ€í™”í•´ë³´ì„¸ìš”. ì†Œí†µì˜ ì¦ê±°ì›€ì„ ëŠë‚„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."},
            {"title": "ğŸ–¼ï¸ ì°½ë°– í’ê²½ ë³´ê¸°", "description": "ì ì‹œ ìŠ¤ë§ˆíŠ¸í°ì—ì„œ ëˆˆì„ ë–¼ê³  ë©€ë¦¬ ìˆëŠ” í’ê²½ì„ ë°”ë¼ë³´ì„¸ìš”. ëˆˆì˜ í”¼ë¡œë„ í’€ë¦¬ê³  ê¸°ë¶„ ì „í™˜ë„ ë©ë‹ˆë‹¤."},
            {"title": "ğŸ“ ì¼ê¸° ì“°ê¸°", "description": "ì˜¤ëŠ˜ ëŠë‚€ ê°ì •ì„ ê¸€ë¡œ ì ì–´ë³´ì„¸ìš”. ì•± ì‚¬ìš© íŒ¨í„´ì„ ìŠ¤ìŠ¤ë¡œ ëŒì•„ë³´ëŠ” ê³„ê¸°ê°€ ë©ë‹ˆë‹¤."},
            {"title": "ğŸµ ìŒì•… ê°ìƒ", "description": "ì¢‹ì•„í•˜ëŠ” ìŒì•…ì„ ë“¤ìœ¼ë©° íœ´ì‹ì„ ì·¨í•˜ì„¸ìš”. ìŠ¤ë§ˆíŠ¸í° í™”ë©´ì„ ë³´ëŠ” ê²ƒë³´ë‹¤ í›¨ì”¬ ë” íë§ì´ ë©ë‹ˆë‹¤."}
        ]
        
        # Randomly pick 2 distinct items
        return random.sample(pool, 2)

    # 6) ìµœì¢… Prediction ë¡œì§ (Updated)
    @staticmethod
    def predict(user, db: Session, emotion: str = None, status: str = None):
        user_id = user.user_id

        # 0) Fetch emotion/status from DB if not provided
        if emotion is None or status is None:
            latest_log = (
                db.query(EmotionStatusLog)
                .filter(EmotionStatusLog.user_id == user_id)
                .order_by(EmotionStatusLog.created_at.desc())
                .first()
            )
            
            if latest_log:
                emotion = latest_log.emotion
                status = latest_log.status
            else:
                # Fallback: ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš© (ì•ˆì „í•œ ê¸°ë³¸ê°’)
                emotion = "GOOD"
                status = "FREE"

        # 1) ìµœê·¼ ì‚¬ìš© ê¸°ë¡
        seq = PredictionEngine.fetch_recent_usage(user_id, db)

        # 2) AI ì—”ì§„ ì‹¤í–‰
        ai_result = PredictionEngine.call_ai_engine(emotion, status, seq)
        
        # Validate AI Result Structure
        required_keys = ["risk_analysis", "usage_prediction", "pattern_detection"]
        is_valid = all(k in ai_result for k in required_keys)

        if not is_valid:
            # Fallback Structure
            risk_analysis = {
                "level": "SAFE", # Enum: SAFE, CAUTION, DANGER
                "score": 0,
                "vulnerable_category": "NONE",
                "condition": emotion,
                "message": "AI ë¶„ì„ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            }
            usage_prediction = {
                "has_prediction": False,
                "start_time": "00:00",
                "end_time": "00:00",
                "target_category": "NONE",
                "probability_percent": 0.0,
                "message": ""
            }
            pattern_detection = {
                "detected": False,
                "pattern_code": "NONE",
                "alert_message": ""
            }
            hourly_forecast = []
        else:
            risk_analysis = ai_result["risk_analysis"]
            usage_prediction = ai_result["usage_prediction"]
            pattern_detection = ai_result["pattern_detection"]
            hourly_forecast = ai_result.get("hourly_forecast", [])
            
            # --- [NEW] Identify Specific Vulnerable App ---
            # AI gives 'SNS', we want 'Instagram' from seq history
            vuln_cat = risk_analysis.get("vulnerable_category", "NONE")
            
            if vuln_cat not in ["NONE", "OTHER"]:
                # Filter sequence for this category
                # seq item: {category, package_name, duration_ms}
                relevant_apps = {}
                for item in seq:
                    # Clean comparison (item['category'] might be 'SNS' or logic needed?)
                    # Assuming item['category'] aligns with model output
                    if item.get("category") == vuln_cat:
                        pkg = item.get("package_name", "Unknown")
                        dur = item.get("duration_ms", 0)
                        relevant_apps[pkg] = relevant_apps.get(pkg, 0) + dur
                
                # Find max
                if relevant_apps:
                    top_app = max(relevant_apps, key=relevant_apps.get)
                    # Clean Name: com.instagram.android -> Instagram
                    simple_name = top_app.split('.')[-1].capitalize()
                    
                    # Update Risk Analysis
                    risk_analysis["vulnerable_category"] = f"{simple_name} ({vuln_cat})"
                    
                    # Update Usage Prediction too if matches
                    if usage_prediction.get("target_category") == vuln_cat:
                         usage_prediction["target_category"] = f"{simple_name} ({vuln_cat})"
            # ---------------------------------------------

            # [NEW] 4) Generate Korean Title & Description based on Level
            # Level: DANGER / CAUTION / SAFE
            level = risk_analysis.get("level", "SAFE")
            vuln_cat_raw = risk_analysis.get("vulnerable_category", "OTHER")
            
            # Map Category to Korean
            # Note: vulnerable_category might be "Instagram (SNS)" now due to above block
            # We want the main category for the sentence? Or just use as is?
            # User request: "ê¸°íƒ€/SNS/ê²Œì„ ì¤‘ ìœ„í—˜ë„ê°€ ë†’ì€ ê²ƒ"
            # If we updated it to "Instagram (SNS)", we might want to just output that? 
            # Or stick to base categories? Let's use the full string if updated, else map base.
            
            cat_map = {"SNS": "SNS", "GAME": "ê²Œì„", "OTHER": "ê¸°íƒ€"}
            
            # If vuln_cat_raw contains '(', it's already "App (Cat)". Let's use it directly or extract.
            # User asked: "(ê¸°íƒ€/SNS/ê²Œì„ ì¤‘ ìœ„í—˜ë„ê°€ ë†’ì€ ê²ƒ)"
            # Let's try to map the base category if possible, or use the raw if it's specific.
            
            # Helper: Get Korean Category Name
            def get_kor_cat(c):
                # Clean up if needed, e.g. "Instagram (SNS)" -> "Instagram" or keep it?
                # User example just said "SNS".
                # If we have specific app, "Instagram" is better than "SNS".
                # Let's use the full text if it's specific, otherwise map base.
                if "(" in c: return c # Use "Instagram (SNS)"
                return cat_map.get(c, c)

            final_cat_kr = get_kor_cat(vuln_cat_raw)

            # Titles & Messages
            if level == "DANGER":
                risk_analysis["title"] = "ìœ„í—˜ë„ ë†’ìŒ"
                risk_analysis["message"] = f"ì˜¤ëŠ˜ì€ {final_cat_kr} ì•± ê³¼ë‹¤ ì‚¬ìš© ìœ„í—˜ë„ê°€ ë†’ì€ ë‚ ì…ë‹ˆë‹¤."
            elif level == "CAUTION":
                risk_analysis["title"] = "ìœ„í—˜ë„ ë³´í†µ"
                risk_analysis["message"] = f"ì˜¤ëŠ˜ì€ {final_cat_kr} ì•± ì‚¬ìš©ì— ì£¼ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤."
            else: # SAFE
                risk_analysis["title"] = "ìœ„í—˜ë„ ë‚®ìŒ"
                risk_analysis["message"] = "ì˜¤ëŠ˜ì€ ìœ„í—˜ë„ê°€ ë‚®ì€ ë‚ ì…ë‹ˆë‹¤."

            # [NEW] 5) Generate Usage Prediction Message
            # "ì˜¤ëŠ˜ì€ (ìœ„í—˜ë„ê°€ ë†’ì€ ì‹œê°„ 1ì‹œê°„ ë²”ìœ„, ex: 22~23)ì‹œì— (ê¸°íƒ€/SNS/ê²Œì„ ì¤‘ ìœ„í—˜ë„ê°€ ë†’ì€ ê²ƒ) ì‚¬ìš© ê°€ëŠ¥ì„±ì´ ë†’ì•„ìš”."
            if usage_prediction.get("has_prediction"):
                s_time = usage_prediction.get("start_time", "00:00") # "22:00"
                e_time = usage_prediction.get("end_time", "00:00")   # "23:00"
                u_cat = usage_prediction.get("target_category", "OTHER")
                u_cat_kr = get_kor_cat(u_cat)
                
                # Parse Hour
                try:
                    s_hour = int(s_time.split(":")[0])
                    e_hour = int(e_time.split(":")[0])
                    time_str = f"{s_hour}~{e_hour}"
                except:
                    time_str = f"{s_time}~{e_time}"
                
                usage_prediction["message"] = f"ì˜¤ëŠ˜ì€ {time_str}ì‹œì— {u_cat_kr} ì•± ì‚¬ìš© ê°€ëŠ¥ì„±ì´ ë†’ì•„ìš”."
            else:
                usage_prediction["message"] = ""
            
            # ---------------------------------------------

        # 3) Generate Recommendations (Backend Logic)
        # AI now returns DANGER/CAUTION/SAFE directly
        current_level = risk_analysis.get("level", "SAFE")
        
        recs = PredictionEngine.get_recommendations(current_level, emotion)
        
        # 5) Log to Database (New Request)
        try:
            # Risk Score/Level Handling
            r_score = float(risk_analysis.get("score", 0))
            r_level = risk_analysis.get("level", "SAFE")
            
            # [NEW] Parse Prediction Times if available
            r_start_time = None
            r_end_time = None
            
            if usage_prediction.get("has_prediction"):
                try:
                    from datetime import datetime, time
                    # We assume the prediction is for "Today" (analysis_date)
                    # analysis_date defaults to today+1 only if not found? 
                    # Actually, let's use date.today() as base since we are predicting for today usually.
                    base_date = date.today()
                    
                    st_str = usage_prediction.get("start_time", "00:00")
                    et_str = usage_prediction.get("end_time", "00:00")
                    
                    # Parse "HH:MM"
                    sh, sm = map(int, st_str.split(':'))
                    eh, em = map(int, et_str.split(':'))
                    
                    r_start_time = time(sh, sm)
                    r_end_time = time(eh, em)
                except Exception as ex:
                    print(f"[TIME PARSE ERROR] {ex}")
            
            # [NEW] Vulnerable App
            r_app = risk_analysis.get("vulnerable_category", "NONE")

            new_log = PredictionLog(
                user_id=user_id,
                input_emotion=emotion,
                input_status=status,
                risk_score=r_score,
                risk_level=r_level,
                risk_app=r_app,
                risk_start_time=r_start_time,
                risk_end_time=r_end_time
            )
            db.add(new_log)
            db.commit()
        except Exception as e:
            print(f"[LOGGING ERROR] {e}")
            db.rollback()



        # 4) Construct Final Response
        return {
            "user_id": user_id,
            "analysis_date": ai_result.get("analysis_date", str(date.today() + timedelta(days=1))),
            "risk_analysis": risk_analysis,
            "usage_prediction": usage_prediction,
            "pattern_detection": pattern_detection,
            "hourly_forecast": hourly_forecast, # For Graph
            "recommendations": recs, # Value add
        }
